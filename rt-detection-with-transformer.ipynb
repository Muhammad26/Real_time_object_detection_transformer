{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1302329,"sourceType":"datasetVersion","datasetId":752534}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics  # RT-DETR is part of Ultralytics (YOLO ecosystem)\nimport torch\nimport cv2\nimport numpy as np\nfrom IPython.display import Video, display\nfrom ultralytics import RTDETR\n\n# -------------------------------------------------\n# Step 1: Load the RT-DETR Model (pretrained on COCO)\n# -------------------------------------------------\nmodel = RTDETR('rtdetr-l.pt')  # Choose from 'rtdetr-l' or 'rtdetr-x'\n\n# -------------------------------------------------\n# Step 2: Process Video Frames\n# -------------------------------------------------\ndef process_video(input_path, output_path):\n    # Open video\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        raise ValueError(\"Could not open video file\")\n    \n    # Get video properties\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    \n    # Define output video writer\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n    \n    # Process each frame\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        # Run RT-DETR inference\n        results = model(frame, conf=0.5)  # Adjust confidence threshold\n        \n        # Draw bounding boxes and labels\n        annotated_frame = results[0].plot()  # Ultralytics auto-visualization\n        \n        # Write frame to output\n        out.write(annotated_frame)\n    \n    # Cleanup\n    cap.release()\n    out.release()\n\n# -------------------------------------------------\n# Step 3: Run on Kaggle (Example)\n# -------------------------------------------------\n# Upload your video to Kaggle first (e.g., \"input_video.mp4\")\ninput_video = \"/kaggle/input/road-traffic-video-monitoring/british_highway_traffic.mp4\"\noutput_video = \"/kaggle/working/output_video.mp4\"\n\nprocess_video(input_video, output_video)\n\n# Display the output video in Kaggle notebook\ndisplay(Video(output_video, embed=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T20:32:29.621480Z","iopub.execute_input":"2025-03-10T20:32:29.621713Z","iopub.status.idle":"2025-03-10T20:34:25.467965Z","shell.execute_reply.started":"2025-03-10T20:32:29.621691Z","shell.execute_reply":"2025-03-10T20:34:25.462277Z"}},"outputs":[],"execution_count":null}]}